{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "#https://www.tensorflow.org/how_tos/using_gpu/\n",
    "#https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow#_=_\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "def get_all_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/cpu:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_available_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected cross entropy loss if the model:\n",
      "('- learns neither dependency:', 0.66156323815798213)\n",
      "('- learns first dependency:  ', 0.51916669970720941)\n",
      "('- learns both dependencies: ', 0.4544543674493905)\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected cross entropy loss if the model:\")\n",
    "print(\"- learns neither dependency:\", -(0.625 * np.log(0.625) +\n",
    "                                      0.375 * np.log(0.375)))\n",
    "# Learns first dependency only ==> 0.51916669970720941\n",
    "print(\"- learns first dependency:  \",\n",
    "      -0.5 * (0.875 * np.log(0.875) + 0.125 * np.log(0.125))\n",
    "      -0.5 * (0.625 * np.log(0.625) + 0.375 * np.log(0.375)))\n",
    "print(\"- learns both dependencies: \", -0.50 * (0.75 * np.log(0.75) + 0.25 * np.log(0.25))\n",
    "      - 0.25 * (2 * 0.50 * np.log (0.50)) - 0.25 * (0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "it turns out that backpropagating errors over too many time steps often causes them to vanish (become insignificantly small) or explode (become overwhelmingly large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, 1, 0, 0, 1, 0, 0, 0]), array([0, 1, 0, 1, 0, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = gen_data(10)\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 5 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4      #each state is represented with a certain width, a vector\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(200), Dimension(5)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(200), Dimension(5), Dimension(2)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_one_hot = tf.one_hot(x, num_classes)  #this is some preprocessing useful for this case only\n",
    "                                        #I guess he wants to play with more than two classes (other than binary)\n",
    "\n",
    "x_one_hot.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unpack:0' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unpack:1' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unpack:2' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unpack:3' shape=(200, 2) dtype=float32>,\n",
       " <tf.Tensor 'unpack:4' shape=(200, 2) dtype=float32>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_inputs = tf.unpack(x_one_hot, axis=1)\n",
    "rnn_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we have a list of five inputs that all(?) are going to play a role in back propagation ??\n",
    "\n",
    "Anyway the important thing is that we have the inputs, or each input each batch, split into the num_steps, number of steps\n",
    "\n",
    "So the final input are 5 separate of them (we chose n=5 above)  \n",
    "and the fact that they have one hot encoding and they have a dimension of two is only related to this particular problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of rnn_cell\n",
    "\n",
    "This is very similar to the __call__ method on Tensorflow's BasicRNNCell. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py\n",
    "\"\"\"\n",
    "\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    #in other words we have the X coming from below which here is num_classes = 2 (it is binary in this case)\n",
    "    #and we also have the state size which is coming from the left\n",
    "    #(previous step in time or just zeros if we are at t=0)\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    \n",
    "    #Well some outputs of the rnn cell are going to the next node at the right.\n",
    "    #These outputs are connected to the next node at the right and of course they have a size of state_size\n",
    "    #as we have defined ourselves as a hyperparameter\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "    \n",
    "    return tf.tanh(tf.matmul(\n",
    "            tf.concat(1, [rnn_input, state]), W\n",
    "            #concat dimension, inputs, so you see that both the state and the inputs are being treated as one\n",
    "        ) + b)\n",
    "    #non linearity chosen here is tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state = init_state\n",
    "rnn_outputs = []\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "    \n",
    "#as we see here the outputs are the state outputs of each rnn.\n",
    "#But here we have set the dimensionality to an arbitrary number of 4, right? so how is this converted back to dim 2?\n",
    "\n",
    "final_state = rnn_outputs[-1]\n",
    "\n",
    "#We just keep the final of the ouputs in a separate variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#so here is the solution, we define these W and b variables only once.\n",
    "#Meaning that the weights and biases are shared for ALL of these rnn_outputs\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorShape([Dimension(200), Dimension(2)]),\n",
       " TensorShape([Dimension(200), Dimension(2)]),\n",
       " TensorShape([Dimension(200), Dimension(2)]),\n",
       " TensorShape([Dimension(200), Dimension(2)]),\n",
       " TensorShape([Dimension(200), Dimension(2)])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "[logit.get_shape() for logit in logits] #these are the logits for the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(200), Dimension(2)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get the predictions for each class we can simply use the softmax function\n",
    "preds = [tf.nn.softmax(logit) for logit in logits] #these are the logits for the outputs\n",
    "preds[0].get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(200)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.nn.softmax_cross_entropy_with_logits\n",
    "#tf.squeeze()\n",
    "#processing of the targets\n",
    "print y.get_shape()\n",
    "\n",
    "#we just get our outputs that we have in a 200x5 fashion and we create 5 separate instances to compare against\n",
    "#each output of the rnn network\n",
    "y_as_list = [tf.squeeze(i, squeeze_dims=[1]) for i in tf.split(1, num_steps, y)]\n",
    "y_as_list[0].get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here we get all losses for all outputs (logits, before they be through softmax) and with the targets\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logit, label) for logit, label in zip(logits, y_as_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_loss = tf.reduce_mean(losses) #we treat all kind of losses equally so we have the total loss here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train step as always we try to minimize the error with some optimizer\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-db2689d6fc85>:3 in train_network.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "('\\nEPOCH', 0)\n",
      "('Average loss at step', 100, 'for last 250 steps:', 0.60203327000141149)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.56343717157840734)\n",
      "('Average loss at step', 300, 'for last 250 steps:', 0.54757148921489718)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.52425423651933667)\n",
      "('Average loss at step', 500, 'for last 250 steps:', 0.51918603748083114)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.52192204833030698)\n",
      "('Average loss at step', 700, 'for last 250 steps:', 0.52050499647855764)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.52384610921144481)\n",
      "('Average loss at step', 900, 'for last 250 steps:', 0.52016591697931291)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa5102f1d90>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFdCAYAAACAfl7+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElSRQwNkiSpIoYGSZJUEUODJEmqyP8HdNNpHYz7sMQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa518054c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(1,num_steps)\n",
    "\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
