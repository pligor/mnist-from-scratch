{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example two-layer classifier models\n",
    "\n",
    "Below example code is given for creating instances of the 10-genre and 25-genre fixed-length input data provider objects and using them to train simple two-layer feedforward network models with rectified linear activations in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "mlpdir = '/home/studenthp/pligor.george@gmail.com/msc_Artificial_Intelligence/mlp_Machine_Learning_Practical/mlpractical'\n",
    "sys.path.append(mlpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named mlp.data_providers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e8661d183801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_providers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMSD10GenreDataProvider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSD25GenreDataProvider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named mlp.data_providers"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from mlp.data_providers import MSD10GenreDataProvider, MSD25GenreDataProvider\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 16011984\n",
    "rng = np.random.RandomState(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSD 10 genre task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = MSD10GenreDataProvider('train', batch_size=50)\n",
    "valid_data = MSD10GenreDataProvider('valid', batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a,b = train_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_layer(inputs, input_dim, output_dim, nonlinearity=tf.nn.relu):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [input_dim, output_dim], stddev=2. / (input_dim + output_dim)**0.5), \n",
    "        'weights')\n",
    "    biases = tf.Variable(tf.zeros([output_dim]), 'biases')\n",
    "    outputs = nonlinearity(tf.matmul(inputs, weights) + biases)    \n",
    "    return outputs, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lamda2 = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, train_data.inputs.shape[1]], 'inputs')\n",
    "targets = tf.placeholder(tf.float32, [None, train_data.num_classes], 'targets')\n",
    "num_hidden = 200\n",
    "\n",
    "with tf.name_scope('fc-layer-1'):\n",
    "    hidden_1, w1 = fully_connected_layer(inputs, train_data.inputs.shape[1], num_hidden)\n",
    "with tf.name_scope('output-layer'):\n",
    "    outputs, w_out = fully_connected_layer(hidden_1, num_hidden, train_data.num_classes, tf.identity)\n",
    "\n",
    "with tf.name_scope('error'):\n",
    "    reg1 = lamda2 * tf.nn.l2_loss(w1)\n",
    "    reg2 = lamda2 * tf.nn.l2_loss(w_out)\n",
    "    \n",
    "    error = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(outputs, targets)) + reg1 + reg2\n",
    "with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(\n",
    "            tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1)), \n",
    "            tf.float32))\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer().minimize(error)\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(10):\n",
    "        running_error = 0.\n",
    "        running_accuracy = 0.\n",
    "        for input_batch, target_batch in train_data:\n",
    "            _, batch_error, batch_acc = sess.run(\n",
    "                [train_step, error, accuracy], \n",
    "                feed_dict={inputs: input_batch, targets: target_batch})\n",
    "            running_error += batch_error\n",
    "            running_accuracy += batch_acc\n",
    "        running_error /= train_data.num_batches\n",
    "        running_accuracy /= train_data.num_batches\n",
    "        print('End of epoch {0:02d}: err(train)={1:.2f} acc(train)={2:.2f}'\n",
    "              .format(e + 1, running_error, running_accuracy))\n",
    "        if (e + 1) % 1 == 0:\n",
    "            valid_error = 0.\n",
    "            valid_accuracy = 0.\n",
    "            for input_batch, target_batch in valid_data:\n",
    "                batch_error, batch_acc = sess.run(\n",
    "                    [error, accuracy], \n",
    "                    feed_dict={inputs: input_batch, targets: target_batch})\n",
    "                valid_error += batch_error\n",
    "                valid_accuracy += batch_acc\n",
    "            valid_error /= valid_data.num_batches\n",
    "            valid_accuracy /= valid_data.num_batches\n",
    "            print('                 err(valid)={0:.2f} acc(valid)={1:.2f}'\n",
    "                   .format(valid_error, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = MSD10GenreDataProvider('train', batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "50*800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_data.num_batches * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlp.data_providers import OneOfKDataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MSD10GenreDataProviderVarLength(OneOfKDataProvider):\n",
    "    \"\"\"Data provider for Million Song Dataset 10-genre classification task.\"\"\"\n",
    "\n",
    "    def __init__(self, which_set='train', batch_size=100, max_num_batches=-1,\n",
    "                 shuffle_order=True, rng=None):\n",
    "        \"\"\"Create a new Million Song Dataset 10-genre data provider object.\n",
    "\n",
    "        Args:\n",
    "            which_set: One of 'train' or 'valid'. Determines which\n",
    "                portion of the MSD 10-genre data this object should provide.\n",
    "            batch_size (int): Number of data points to include in each batch.\n",
    "            max_num_batches (int): Maximum number of batches to iterate over\n",
    "                in an epoch. If `max_num_batches * batch_size > num_data` then\n",
    "                only as many batches as the data can be split into will be\n",
    "                used. If set to -1 all of the data will be used.\n",
    "            shuffle_order (bool): Whether to randomly permute the order of\n",
    "                the data before each epoch.\n",
    "            rng (RandomState): A seeded random number generator.\n",
    "        \"\"\"\n",
    "        # check a valid which_set was provided\n",
    "        assert which_set in ['train', 'valid'], (\n",
    "            'Expected which_set to be either train or valid. '\n",
    "            'Got {0}'.format(which_set)\n",
    "        )\n",
    "        self.which_set = which_set\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        # construct path to data using os.path.join to ensure the correct path\n",
    "        # separator for the current platform / OS is used\n",
    "        # MLP_DATA_DIR environment variable should point to the data directory\n",
    "        data_path = os.path.join(\n",
    "            os.environ['MLP_DATA_DIR'], 'msd-10-genre-%s-var-length.npz' % which_set\n",
    "        )\n",
    "\n",
    "        assert os.path.isfile(data_path), (\n",
    "            'Data file does not exist at expected path: ' + data_path\n",
    "        )\n",
    "        \n",
    "        # load data from compressed numpy file\n",
    "        loaded = np.load(data_path)\n",
    "        inputs, targets = loaded['inputs'], loaded['targets']\n",
    "        \n",
    "        # flatten inputs to vectors and upcast to float32\n",
    "        inputs = inputs.reshape((inputs.shape[0], -1)).astype('float32')\n",
    "        \n",
    "        # label map gives strings corresponding to integer label targets\n",
    "        self.label_map = loaded['label_map']\n",
    "        \n",
    "        self.shuffle_order = shuffle_order\n",
    "        self.rng = rng\n",
    "        \n",
    "        # pass the loaded data to the parent class __init__\n",
    "        #super(MSD10GenreDataProviderVarLength, self).__init__()\n",
    "        \n",
    "        #inputs, targets, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b = train_data.next()\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "which_set = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(\n",
    "            os.environ['MLP_DATA_DIR'], 'msd-10-genre-%s-var-length.npz' % which_set\n",
    "        )\n",
    "\n",
    "assert os.path.isfile(data_path), (\n",
    "    'Data file does not exist at expected path: ' + data_path\n",
    ")\n",
    "    \n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loaded = np.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loaded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_order = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_lens = 3 # None for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lens = np.array([250, 500, 650, 800, 950, 1200, 2000, 4000])\n",
    "\n",
    "if keep_lens is None:\n",
    "    assert len(lens) == 8\n",
    "else:\n",
    "    lens = lens[:keep_lens]\n",
    "\n",
    "if shuffle_order:\n",
    "    lens = rng.permutation(lens)\n",
    "else:\n",
    "    lens.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_prefix = 'inputs_'\n",
    "targets_prefix = 'targets_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curTargets = [(targets_prefix + str(l)) for l in lens]\n",
    "curTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numInstances = np.sum([len(loaded[t])  for t in curTargets])\n",
    "numInstances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arange(len(loaded['targets_250']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_order = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = np.dtype([('group', np.int), ('ind', np.int)])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a = np.empty(2, dtype=dt)\n",
    "# a[0] = 640, 5\n",
    "# a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_mapping = np.empty(numInstances, dtype = dt)\n",
    "loc = 0\n",
    "for l, t in zip(lens, curTargets):\n",
    "    curLength = len(loaded[t])\n",
    "    inds = np.arange(curLength).astype(np.int)\n",
    "    if shuffle_order:\n",
    "        inds = rng.permutation(inds)\n",
    "        \n",
    "    tuples = zip(np.repeat(l, curLength), inds)\n",
    "    \n",
    "    index_mapping[loc:curLength + loc] = tuples\n",
    "    \n",
    "    loc = curLength + loc\n",
    "        \n",
    "index_mapping[110:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ind_mapping = index_mapping[110:130]\n",
    "test_ind_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in test_ind_mapping:\n",
    "    group, ind = x\n",
    "    inputs = loaded[inputs_prefix + str(group)][ind]\n",
    "    print inputs.shape\n",
    "    outputs = loaded[targets_prefix + str(group)][ind]\n",
    "    print outputs[()]#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.reshape(test_ind_mapping, (5, -1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loaded['label_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = a[()] #a way to get the value from a zero-dim array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputKeys = [key for key in loaded.keys() if \"inputs\" in key]\n",
    "inputKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targetKeys = [key for key in loaded.keys() if \"targets\" in key]\n",
    "targetKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
